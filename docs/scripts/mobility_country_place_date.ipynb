{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "\n",
    "\n",
    "file_path = \"../data/Global_Mobility_Report.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# country ->\n",
    "#   date -> (grocery_pharmacy, park, residential, retail_recreation, transit_station, workplace)\n",
    "\n",
    "places = [\"grocery_pharmacy\", \"park\", \"residential\", \"retail_recreation\", \"transit_station\", \"workplace\"]\n",
    "\n",
    "raw_data = OrderedDict()\n",
    "dates = set()\n",
    "# Open the file in read mode\n",
    "with open(file_path, \"r\") as file:\n",
    "    reader = csv.reader(file)\n",
    "\n",
    "    # Iterate over each row in the CSV file\n",
    "    for r in reader:\n",
    "        country = r[1]\n",
    "        province = r[2]\n",
    "\n",
    "        if country == \"country_region\":\n",
    "            continue\n",
    "\n",
    "        if province != \"\":\n",
    "            continue\n",
    "\n",
    "        date = r[8]\n",
    "        dates.add(date)\n",
    "\n",
    "        retail_recreation = float(r[9]) / 100 if r[9] != \"\" else 999.0\n",
    "        grocery_pharmacy = float(r[10]) / 100 if r[10] != \"\" else 999.0\n",
    "        park = float(r[11]) / 100 if r[11] != \"\" else 999.0\n",
    "        transit_station = float(r[12]) / 100 if r[12] != \"\" else 999.0\n",
    "        workplace = float(r[13]) / 100 if r[13] != \"\" else 999.0\n",
    "        residential = float(r[14]) / 100 if r[14] != \"\" else 999.0\n",
    "\n",
    "        # country\n",
    "        if raw_data.get(country) == None:\n",
    "            raw_data[country] = OrderedDict()\n",
    "            for p in places:\n",
    "                raw_data[country][p] = OrderedDict()\n",
    "        \n",
    "        # date\n",
    "        for p in places:\n",
    "            if raw_data[country][p].get(date) == None:\n",
    "                raw_data[country][p][date] = []\n",
    "\n",
    "        \n",
    "        # places\n",
    "        if grocery_pharmacy != 999.0:\n",
    "            raw_data[country][\"grocery_pharmacy\"][date].append(grocery_pharmacy)\n",
    "        if park != 999.0:\n",
    "            raw_data[country][\"park\"][date].append(park)\n",
    "        if residential != 999.0:\n",
    "            raw_data[country][\"residential\"][date].append(residential)\n",
    "        if retail_recreation != 999.0:\n",
    "            raw_data[country][\"retail_recreation\"][date].append(retail_recreation)\n",
    "        if transit_station != 999.0:\n",
    "            raw_data[country][\"transit_station\"][date].append(transit_station)\n",
    "        if workplace != 999.0:\n",
    "            raw_data[country][\"workplace\"][date].append(workplace)\n",
    "\n",
    "date_sorted = sorted(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average multiple values for each date\n",
    "# fill in missing dates\n",
    "mobility_data = OrderedDict()\n",
    "\n",
    "for country in raw_data:\n",
    "    mobility_data[country] = OrderedDict()\n",
    "    for category in raw_data[country]:\n",
    "        mobility_data[country][category] = OrderedDict()\n",
    "        for date in raw_data[country][category]:\n",
    "            if len(raw_data[country][category][date]) == 0:\n",
    "                continue\n",
    "            perc = sum(raw_data[country][category][date]) / len(raw_data[country][category][date])\n",
    "            mobility_data[country][category][date] = perc\n",
    "        \n",
    "        # fill in missing dates \n",
    "        prev = 0.0\n",
    "        for date in date_sorted:\n",
    "            if mobility_data[country][category].get(date) == None:\n",
    "                mobility_data[country][category][date] = prev\n",
    "            prev = mobility_data[country][category][date]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the ordered map to a standard dictionary\n",
    "standard_dict = dict(mobility_data)\n",
    "\n",
    "# Save the standard dictionary as JSON\n",
    "file_path = \"../data/mobility_country_place_date.json\"\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(standard_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f = open(\"../data/mobility_country_place_date.json\")\n",
    "data = json.load(f)\n",
    "data\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.98 -1.0\n"
     ]
    }
   ],
   "source": [
    "mx = -1\n",
    "mn = 1\n",
    "ca = \"grocery_pharmacy\"\n",
    "for country in data:\n",
    "    for date in data[country][ca]:\n",
    "        if data[country][ca][date] > mx:\n",
    "            mx = data[country][ca][date]\n",
    "        if data[country][ca][date] < mn:\n",
    "            mn = data[country][ca][date]\n",
    "print(mx,mn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dates = list(data['United Arab Emirates']['grocery_pharmacy'].keys())\n",
    "countries = list(data.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_data = OrderedDict()\n",
    "m = 0\n",
    "c = ''\n",
    "\n",
    "with open(\"../../../JHU_COVID-19.csv\", \"r\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    for r in reader:\n",
    "        country = r[0]\n",
    "        province = r[1]\n",
    "        if country not in countries:\n",
    "            continue\n",
    "\n",
    "        if province != \"\":\n",
    "            continue\n",
    "        date = r[4][:10]\n",
    "        cases = int(r[6])\n",
    "        long = r[7]\n",
    "        if long == \"\":\n",
    "            long = 0.0\n",
    "        else:\n",
    "            long = float(long)\n",
    "        lat = r[8]\n",
    "        if lat == \"\":\n",
    "            lat = 0.0\n",
    "        else:\n",
    "            lat = float(lat)\n",
    "        \n",
    "        if country == \"United States\":\n",
    "            long = -95.7\n",
    "            lat = 37.1\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "            \n",
    "        if raw_data.get(country) == None:\n",
    "            raw_data[country] = OrderedDict()\n",
    "            \n",
    "        \n",
    "        if date in dates:\n",
    "            #print(date)\n",
    "            raw_data[country][date] = [cases, long, lat]\n",
    "            \n",
    "\n",
    "for country in raw_data:\n",
    "    prev = [0,0.0,0.0]\n",
    "    for date in dates:\n",
    "        if raw_data[country].get(date) == None:\n",
    "            raw_data[country][date] = prev\n",
    "        prev = raw_data[country][date]\n",
    "\n",
    "for country in raw_data:\n",
    "    for date in dates:\n",
    "        if m < raw_data[country][date][0]:\n",
    "            m = raw_data[country][date][0]\n",
    "\n",
    "standard_dict = dict(raw_data)\n",
    "\n",
    "# Save the standard dictionary as JSON\n",
    "file_path = \"../data/case_country_date.json\"\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(standard_dict, file, indent=4, sort_keys=True)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6399531"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = OrderedDict()\n",
    "for date in dates:\n",
    "    s = 0\n",
    "    for c in countries:\n",
    "        if c in raw_data.keys():\n",
    "            s =  s + raw_data[c][date][0]\n",
    "    data[date] = s\n",
    "\n",
    "standard_dict = dict(data)\n",
    "\n",
    "# Save the standard dictionary as JSON\n",
    "file_path = \"../data/case_date.json\"\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(standard_dict, file, indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "c0faf152806832bd3eb6fa0f96e0ded2176b39cb01d46800a688dc1ba9f84874"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
